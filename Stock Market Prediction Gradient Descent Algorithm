function theta = dogradientdescent(lambda,learningrate,nriterations,traindata,displayon);
% USAGE: theta = dogradientdescent(lambda,learningrate,nriterations,traindata,displayon);

myeps = 0.0001;

% Compute the row vector of desired responses
n = length(traindata);
ydesired = traindata(3:n);

% Compute a matrix such that column t of of the matrix
% is the input pattern which you want to use to predict 
% element t of the vector "desired responses".
sinputmatrix = [];
for t = 3:n,
    sinputvector = [traindata(t-1); traindata(t-2); 1];
    sinputmatrix = [sinputmatrix sinputvector];
end;

%  Implement the Batch Gradient Descent Algorithm 
theta = zeros(3,1);
begintimer = tic;
for iteration = 1:nriterations,
    % Compute Prediction Error
    error(iteration) = 0;
    nminus2 = n - 2;
    for t = 1:nminus2;
        ypredicted(t) = theta(1)*sinputmatrix(1,t) + theta(2)*sinputmatrix(2,t) + theta(3)*sinputmatrix(3,t);
        thetamag = sqrt(theta(1)*theta(1)+myeps) + sqrt(theta(2)*theta(2)+myeps) + sqrt(theta(3)*theta(3)+myeps);
        error(iteration) = error(iteration) + ((lambda*thetamag) / nminus2) + (lambda * ((ydesired(t) - ypredicted(t)*(ydesired(t) - ypredicted(t)))));  % STUDENT FIX THIS ERROR CALCULATION
    end;
    
    
    % Compute Derivative of Error Function
    thederivative = zeros(3,1);
    for t = 1:nminus2,
        ypredicted(t) = theta(1)*sinputmatrix(1,t) + theta(2)*sinputmatrix(2,t) + theta(3)*sinputmatrix(3,t);
        thederivative(1) = thederivative(1) - (2/(n-2))*(ydesired(t) - ypredicted(t))*sinputmatrix(1,t) + lambda*theta(1)/((n-2)*sqrt(theta(1)*theta(1)+myeps));       
        thederivative(2) = thederivative(2) - (2/(n-2))*(ydesired(t) - ypredicted(t))*sinputmatrix(2,t) + lambda*theta(2)/((n-2)*sqrt(theta(2)*theta(2)+myeps));  
        thederivative(3) = thederivative(3) -(2/(n-2))*(ydesired(t) - ypredicted(t)) + lambda*theta(3)/((n-2)*sqrt(theta(3)*theta(3)+myeps));
    end;
    if displayon,
        disp(['Iteration #',num2str(iteration),': Error = ',num2str(error(iteration)),' Gradient Norm =',num2str(max(abs(thederivative)))]);    
    end;
   
    % Take Gradient Descent Step
    theta = theta - learningrate*thederivative;   % STUDENT PLEASE FIX  TO IMPLEMENT GRADIENT DESCENT STEP
end;
computetime = toc(begintimer);
disp(['Parameter Estimates computed in ',num2str(computetime),' seconds using gradient descent.']);
disp(['Final Prediction Error =',num2str(error(iteration)),', Final Gradient Norm = ',num2str(max(abs(thederivative)))]);
disp('----------------------------------------------------------');

