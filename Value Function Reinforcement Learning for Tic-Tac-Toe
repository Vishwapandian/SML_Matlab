function risk = empiricalrisk(theta,smatrix,rvector,mu)
    function y = sig(x)
        y = 1/(1+exp(-x));
    end
% BEGIN MAIN PROGRAM
% The ith "episode" during the learning process is the triple
% [smatrix(:,i-1), smatrix(:,i), r(i)] where
% smatrix(:,i-1) is previous board state vector, smatrix(:,i) is the current
% board state vector, and r(i) is the scalar reinforcement signal received
% by the learning machine from the environment when the machine transitions from
% board state vector "smatrix(:,i-1)" to board state vector "smatrix(:,i)".
%
% "theta" is a column vector with dimension equal to the number of rows of "smatrix"
% "mu" is the discount factorj
    theta = theta(:); % force theta to be a column vector
    [inputdim,nrepisodes] = size(smatrix);
    sumrisk = 0;
    for i = 2:nrepisodes,
        sminus1 = smatrix(:,i-1);
        s = smatrix(:,i);
        ri = rvector(i);
        % Student modify following line of MATLAB code to compute loss per episode ci
        ci = ri - (theta'*sminus1 - (mu*theta'*s)); % Student fix this line of code.
        sumrisk = sumrisk + ci*ci;
    end;
    risk = sumrisk/(nrepisodes-1); 
end
